{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import team, game as g\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Used for developing visual of Random Forest if desired\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Summary\n",
    "\n",
    "#### Our goal from this analysis will be to predict the outcome of March Madness games. To do this, we will be using a Random Forest that takes in historical data from NCAA tourney matchups as input and outputs predictions for the winning team for each game in a March Madness tournament. \n",
    "\n",
    "### Baseline Model\n",
    "#### The baseline model we will use to compare our model's results against will be solely tied to a team's RPI. Our baseline model poses the following hypothesis: : \n",
    "That in any NCAA tournament game, the team with the lower RPI will win the game. \n",
    "Intuitively, this is a reasonable prediction. RPI (Ratings Percentage Index), ranks teams based on their wins, losses, and strength of schedule for the past season. If team A has a lower RPI than team B at the end of a season, it is fair to assume that team A's performance throughout the season has been at a higher level than team B's. For this reason, we can guess that any new basketball fan watching their first March Madness tournament would choose team A over team B in a game, disregarding any other biases.\n",
    "\n",
    "### Random Forest Approach\n",
    "We would like to build on our baseline model and see if we can develop an approach that more accurately predicts the outcome of games. One of the most exciting parts of March Madness is the array of upsets that occur throughout the tournament. In general, upsets occur when a team with a higher RPI beats a team with a lower RPI. We would like to create a model that performs better than our baseline model by more accurately predicting the outcome of games, in particular predicting when upsets occur. For us to accomplish this, we can utilize RPI as well as some additional attributes that provide more information surrounding each team's level of performance in the past season. These factors can be used to build a random forest in order to: \n",
    "1) Identify which factors are correlated to predicting the outcome of a game\n",
    "2) Predict when an upset is going to occur in March Madness\n",
    "\n",
    "We will build a random forest by passing as input a data frame where each row corresponds to an NCAA tournament game. Each row will contain data regarding each team's yearly averages and totals in statistical categories, RPI, the game's outcome, and whether or not the team with the lowest RPI won. This last piece of information will be our dependent variable. The random forest will utilize each feature in our training data set describing the winning team and losing team's performance during the season, in order to learn which factors are tied to predicting the outcome of a game. Once the random forest has been trained, tournament data where the outcome of the each game has been excluded can be used as input to the model to generate a set of predictions for each game in that year's tournament.\n",
    "\n",
    "### Data Sources Overview\n",
    "- Kaggle provided\n",
    "\n",
    "### Data Cleansing/Preparation\n",
    "- Description of chosen statistical categories to use in model\n",
    "- Finding yearly averages/totals for each team\n",
    "\n",
    "### Random Forest Creation\n",
    "- Created 15 years worth of predictions\n",
    "- Parameter Selection\n",
    "    - OOB when creating RF each time\n",
    "    - Max features\n",
    "    - n trees\n",
    "\n",
    "### Model Results\n",
    "- 15 Year comparison with baseline model\n",
    "- Championship game predictions vs. baseline model\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNCAATeamiIds():\n",
    "    \"\"\"\n",
    "    Read in results of NCAA games and assign each result an id \n",
    "    for the winning team and losing team. Output a dictionary with each team's ID\n",
    "    \"\"\"\n",
    "    ncaaTourneyTeams = {}\n",
    "    ncaaTournResults = pd.read_csv(\"data/NCAATourneyCompactResults.csv\")\n",
    "    for index, row in ncaaTournResults.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "\n",
    "        if customWId not in ncaaTourneyTeams:\n",
    "            ncaaTourneyTeams[customWId] = 1\n",
    "        if customLId not in ncaaTourneyTeams:\n",
    "            ncaaTourneyTeams[customLId] = 1\n",
    "    return ncaaTourneyTeams\n",
    "\n",
    "def getTeamNames():\n",
    "    \"\"\"\n",
    "    Return dictionary where key is team ID and value is team name\n",
    "    \"\"\"\n",
    "    names = {}\n",
    "    teams = pd.read_csv(\"Data/Teams.csv\")\n",
    "    for index, row in teams.iterrows():\n",
    "        teamId = row[\"TeamID\"]\n",
    "        name = row[\"TeamName\"]\n",
    "        names[teamId] = name\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeasonStats(ncaaTourneyTeams):\n",
    "    \"\"\"\n",
    "    Use regular season results and RPI rankings to create a \n",
    "    dictionary where key is the team's ID and the value is a \n",
    "    Team object. Team objects contain yearly avg stats for each \n",
    "    team in various categories.\n",
    "    \"\"\"\n",
    "    teams = {}\n",
    "    names = getTeamNames()\n",
    "    unfiltRanks = pd.read_csv(\"data/MasseyOrdinals_Prelim2018.csv\")\n",
    "    rankings = unfiltRanks[(unfiltRanks[\"SystemName\"] == \"RPI\") & (unfiltRanks[\"RankingDayNum\"] == 133)]\n",
    "    regSeasonResults = pd.read_csv(\"data/RegularSeasonDetailedResults.csv\")\n",
    "    for index, row in regSeasonResults.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "        wRPI = None\n",
    "        lRPI = None\n",
    "        try:\n",
    "            wRPI = rankings[(rankings[\"Season\"] == season) & (rankings[\"TeamID\"] == wTeamId)].iloc[0][\"OrdinalRank\"]\n",
    "            lRPI = rankings[(rankings[\"Season\"] == season) & (rankings[\"TeamID\"] == lTeamId)].iloc[0][\"OrdinalRank\"]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print str(lTeamId) + \" \" + str(season) + \" not found\"\n",
    "        \n",
    "        if customWId not in teams:\n",
    "            teams[customWId] = team.Team(customWId)\n",
    "        if customLId not in teams:\n",
    "            teams[customLId] = team.Team(customLId)\n",
    "        wTeam = teams[customWId]\n",
    "        wTeam.RPI = wRPI\n",
    "        wTeam.name = names[wTeamId]\n",
    "        wTeam.updateStats(row, True)\n",
    "        if customLId in ncaaTourneyTeams:\n",
    "            wTeam.winsVsTourney += 1\n",
    "        lTeam = teams[customLId]\n",
    "        lTeam.name = names[lTeamId]\n",
    "        lTeam.RPI = lRPI\n",
    "        lTeam.updateStats(row, False)\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatchups(teams):\n",
    "    \"\"\"\n",
    "    Use NCAA Tournament results to return data frame of matchups where each row contains data for one matchup between two teams, including their yearly avg totals in statistical categories, RPI, and game result.\n",
    "    \"\"\"\n",
    "    matchups = []\n",
    "    ncaaTournResults = pd.read_csv(\"data/NCAATourneyCompactResults.csv\")\n",
    "    for index, row in ncaaTournResults.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "\n",
    "        if customWId in teams and customLId in teams:\n",
    "            wTeamData = teams[customWId].objToDict().copy()\n",
    "            for key in wTeamData.keys():\n",
    "                wTeamData[\"w\" + key] = wTeamData[key]\n",
    "                del wTeamData[key]\n",
    "            lTeamData = teams[customLId].objToDict().copy()\n",
    "            for key in lTeamData.keys():\n",
    "                lTeamData[\"l\" + key] = lTeamData[key]\n",
    "                del lTeamData[key]\n",
    "            matchupData = wTeamData.copy()\n",
    "            matchupData.update(lTeamData)\n",
    "            matchupData[\"dayNum\"] = dayNum\n",
    "            matchupData[\"season\"] = season\n",
    "            matchups.append(matchupData)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(matchups)\n",
    "    return df\n",
    "\n",
    "def getMatchupData():\n",
    "    \"\"\"\n",
    "    Returns data frame of historical matchups in NCAA tournament.\n",
    "    Reads in existing CSV if available. Otherwise, produces data frame by creating Team objects, calculating yearly avg totals for each team, and joining with historical NCAA tourney matchup data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matchups = pd.read_csv(\"Data/output/matchups.csv\")\n",
    "        return matchups\n",
    "    except Exception as e:\n",
    "        ncaaTourneyTeams = populateNCAATourneyTeams()\n",
    "        teamObjs = getSeasonStats(ncaaTourneyTeams)\n",
    "        matchups = getMatchups(teamObjs)\n",
    "        matchups.to_csv(\"Data/output/matchups.csv\", index=False)\n",
    "        return matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findChampionshipMatches():\n",
    "    \"\"\"\n",
    "    Read in NCAA tourney matchups and return data frame containing additional column denoting (True/False) if that matchup was a championship game. \n",
    "    \"\"\"\n",
    "    matchups = getMatchupData()\n",
    "    ## group by season and with resulting groupby obj, find whether each row equals the dayNum max for each group\n",
    "    ## store result as column in matchups defining whether championship played that day\n",
    "    ## able to pass in functions to transform to perform calculations for each group\n",
    "    matchups[\"chipGame\"] = matchups.groupby(['season'])['dayNum'].transform(max) == matchups['dayNum']\n",
    "    return matchups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayNum</th>\n",
       "      <th>lDRB</th>\n",
       "      <th>lEFG</th>\n",
       "      <th>lFTA</th>\n",
       "      <th>lFTP</th>\n",
       "      <th>lMOL</th>\n",
       "      <th>lMOV</th>\n",
       "      <th>lORB</th>\n",
       "      <th>lPOSS</th>\n",
       "      <th>lRPI</th>\n",
       "      <th>...</th>\n",
       "      <th>wTO</th>\n",
       "      <th>wTOF</th>\n",
       "      <th>w_id</th>\n",
       "      <th>wconfTournWins</th>\n",
       "      <th>wdEff</th>\n",
       "      <th>wname</th>\n",
       "      <th>wnumGamesPlayed</th>\n",
       "      <th>woEff</th>\n",
       "      <th>wwinsVsTourney</th>\n",
       "      <th>chipGame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>154</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>24.133333</td>\n",
       "      <td>0.661631</td>\n",
       "      <td>5.867986</td>\n",
       "      <td>23.581709</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>72.553333</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.620690</td>\n",
       "      <td>14.448276</td>\n",
       "      <td>1393_2003</td>\n",
       "      <td>2</td>\n",
       "      <td>98.529129</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>29</td>\n",
       "      <td>112.749541</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>154</td>\n",
       "      <td>26.093750</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.681974</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>19.534958</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>71.668750</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>13.787879</td>\n",
       "      <td>12.424242</td>\n",
       "      <td>1163_2004</td>\n",
       "      <td>3</td>\n",
       "      <td>89.885700</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>33</td>\n",
       "      <td>111.097074</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>154</td>\n",
       "      <td>23.393939</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17.151515</td>\n",
       "      <td>0.725846</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>17.893417</td>\n",
       "      <td>10.969697</td>\n",
       "      <td>64.618182</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.677419</td>\n",
       "      <td>19.032258</td>\n",
       "      <td>1314_2005</td>\n",
       "      <td>2</td>\n",
       "      <td>91.615572</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>31</td>\n",
       "      <td>115.602174</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>154</td>\n",
       "      <td>22.090909</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>19.212121</td>\n",
       "      <td>0.699394</td>\n",
       "      <td>2.593530</td>\n",
       "      <td>12.360264</td>\n",
       "      <td>10.878788</td>\n",
       "      <td>62.109091</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>14.878788</td>\n",
       "      <td>16.272727</td>\n",
       "      <td>1196_2006</td>\n",
       "      <td>4</td>\n",
       "      <td>95.169808</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33</td>\n",
       "      <td>116.501456</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>154</td>\n",
       "      <td>24.515152</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>19.606061</td>\n",
       "      <td>0.702470</td>\n",
       "      <td>3.323661</td>\n",
       "      <td>16.869421</td>\n",
       "      <td>11.181818</td>\n",
       "      <td>64.115152</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.470588</td>\n",
       "      <td>1196_2007</td>\n",
       "      <td>4</td>\n",
       "      <td>92.638035</td>\n",
       "      <td>Florida</td>\n",
       "      <td>34</td>\n",
       "      <td>119.599871</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>154</td>\n",
       "      <td>26.676471</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>23.852941</td>\n",
       "      <td>0.596792</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>19.755656</td>\n",
       "      <td>14.117647</td>\n",
       "      <td>69.394118</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12.909091</td>\n",
       "      <td>15.848485</td>\n",
       "      <td>1242_2008</td>\n",
       "      <td>4</td>\n",
       "      <td>88.485578</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>33</td>\n",
       "      <td>116.404478</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>154</td>\n",
       "      <td>24.937500</td>\n",
       "      <td>0.429577</td>\n",
       "      <td>23.312500</td>\n",
       "      <td>0.698263</td>\n",
       "      <td>10.656257</td>\n",
       "      <td>15.333729</td>\n",
       "      <td>13.968750</td>\n",
       "      <td>65.168750</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.709677</td>\n",
       "      <td>1314_2009</td>\n",
       "      <td>2</td>\n",
       "      <td>96.797445</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>31</td>\n",
       "      <td>118.741033</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>154</td>\n",
       "      <td>23.593750</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>23.937500</td>\n",
       "      <td>0.741678</td>\n",
       "      <td>3.209877</td>\n",
       "      <td>12.074432</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>62.918750</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>11.117647</td>\n",
       "      <td>14.794118</td>\n",
       "      <td>1181_2010</td>\n",
       "      <td>4</td>\n",
       "      <td>91.111407</td>\n",
       "      <td>Duke</td>\n",
       "      <td>34</td>\n",
       "      <td>115.043575</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>154</td>\n",
       "      <td>24.064516</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>21.451613</td>\n",
       "      <td>0.724850</td>\n",
       "      <td>10.281282</td>\n",
       "      <td>13.577203</td>\n",
       "      <td>10.870968</td>\n",
       "      <td>64.806452</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>11.742857</td>\n",
       "      <td>12.142857</td>\n",
       "      <td>1163_2011</td>\n",
       "      <td>5</td>\n",
       "      <td>99.982906</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>35</td>\n",
       "      <td>110.543668</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>154</td>\n",
       "      <td>25.787879</td>\n",
       "      <td>0.467213</td>\n",
       "      <td>22.545455</td>\n",
       "      <td>0.696358</td>\n",
       "      <td>5.575745</td>\n",
       "      <td>19.243111</td>\n",
       "      <td>11.121212</td>\n",
       "      <td>66.109091</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>11.352941</td>\n",
       "      <td>11.882353</td>\n",
       "      <td>1246_2012</td>\n",
       "      <td>3</td>\n",
       "      <td>86.961502</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>34</td>\n",
       "      <td>112.715253</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>154</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.695303</td>\n",
       "      <td>1.961083</td>\n",
       "      <td>17.188919</td>\n",
       "      <td>10.593750</td>\n",
       "      <td>62.787500</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>12.676471</td>\n",
       "      <td>18.705882</td>\n",
       "      <td>1257_2013</td>\n",
       "      <td>4</td>\n",
       "      <td>86.112925</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>34</td>\n",
       "      <td>109.252751</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>154</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.681187</td>\n",
       "      <td>3.098252</td>\n",
       "      <td>17.185279</td>\n",
       "      <td>14.647059</td>\n",
       "      <td>65.352941</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>11.676471</td>\n",
       "      <td>12.911765</td>\n",
       "      <td>1163_2014</td>\n",
       "      <td>2</td>\n",
       "      <td>97.159181</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>34</td>\n",
       "      <td>110.555255</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>154</td>\n",
       "      <td>24.205882</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>18.764706</td>\n",
       "      <td>0.774120</td>\n",
       "      <td>1.632353</td>\n",
       "      <td>18.306100</td>\n",
       "      <td>9.470588</td>\n",
       "      <td>58.182353</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>11.242424</td>\n",
       "      <td>12.575758</td>\n",
       "      <td>1181_2015</td>\n",
       "      <td>2</td>\n",
       "      <td>99.294094</td>\n",
       "      <td>Duke</td>\n",
       "      <td>33</td>\n",
       "      <td>121.892002</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>154</td>\n",
       "      <td>26.941176</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>20.735294</td>\n",
       "      <td>0.740297</td>\n",
       "      <td>1.555030</td>\n",
       "      <td>16.701934</td>\n",
       "      <td>14.029412</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.117647</td>\n",
       "      <td>13.852941</td>\n",
       "      <td>1437_2016</td>\n",
       "      <td>3</td>\n",
       "      <td>95.410072</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>34</td>\n",
       "      <td>115.004811</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>154</td>\n",
       "      <td>30.939394</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>22.424242</td>\n",
       "      <td>0.731215</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>24.421108</td>\n",
       "      <td>9.363636</td>\n",
       "      <td>69.545455</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.878788</td>\n",
       "      <td>13.545455</td>\n",
       "      <td>1314_2017</td>\n",
       "      <td>2</td>\n",
       "      <td>97.232471</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>33</td>\n",
       "      <td>115.555253</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dayNum       lDRB      lEFG       lFTA      lFTP       lMOL       lMOV  \\\n",
       "63      154  26.900000  0.408333  24.133333  0.661631   5.867986  23.581709   \n",
       "127     154  26.093750  0.590909  23.000000  0.681974   3.114224  19.534958   \n",
       "191     154  23.393939  0.500000  17.151515  0.725846   0.033333  17.893417   \n",
       "255     154  22.090909  0.683673  19.212121  0.699394   2.593530  12.360264   \n",
       "319     154  24.515152  0.562500  19.606061  0.702470   3.323661  16.869421   \n",
       "383     154  26.676471  0.783019  23.852941  0.596792   0.148148  19.755656   \n",
       "447     154  24.937500  0.429577  23.312500  0.698263  10.656257  15.333729   \n",
       "511     154  23.593750  0.728261  23.937500  0.741678   3.209877  12.074432   \n",
       "578     154  24.064516  0.590000  21.451613  0.724850  10.281282  13.577203   \n",
       "645     154  25.787879  0.467213  22.545455  0.696358   5.575745  19.243111   \n",
       "712     154  24.312500  0.464912  16.500000  0.695303   1.961083  17.188919   \n",
       "779     154  26.500000  0.421569  30.000000  0.681187   3.098252  17.185279   \n",
       "846     154  24.205882  0.740385  18.764706  0.774120   1.632353  18.306100   \n",
       "913     154  26.941176  0.585106  20.735294  0.740297   1.555030  16.701934   \n",
       "980     154  30.939394  0.583333  22.424242  0.731215   0.266667  24.421108   \n",
       "\n",
       "          lORB      lPOSS  lRPI    ...           wTO       wTOF       w_id  \\\n",
       "63   14.300000  72.553333     6    ...     13.620690  14.448276  1393_2003   \n",
       "127  11.375000  71.668750    16    ...     13.787879  12.424242  1163_2004   \n",
       "191  10.969697  64.618182     2    ...     16.677419  19.032258  1314_2005   \n",
       "255  10.878788  62.109091    10    ...     14.878788  16.272727  1196_2006   \n",
       "319  11.181818  64.115152     1    ...     14.000000  13.470588  1196_2007   \n",
       "383  14.117647  69.394118     3    ...     12.909091  15.848485  1242_2008   \n",
       "447  13.968750  65.168750     6    ...     13.000000  15.709677  1314_2009   \n",
       "511   9.250000  62.918750    12    ...     11.117647  14.794118  1181_2010   \n",
       "578  10.870968  64.806452    33    ...     11.742857  12.142857  1163_2011   \n",
       "645  11.121212  66.109091     6    ...     11.352941  11.882353  1246_2012   \n",
       "712  10.593750  62.787500    20    ...     12.676471  18.705882  1257_2013   \n",
       "779  14.647059  65.352941    17    ...     11.676471  12.911765  1163_2014   \n",
       "846   9.470588  58.182353     4    ...     11.242424  12.575758  1181_2015   \n",
       "913  14.029412  69.500000     5    ...     11.117647  13.852941  1437_2016   \n",
       "980   9.363636  69.545455     8    ...     11.878788  13.545455  1314_2017   \n",
       "\n",
       "     wconfTournWins      wdEff           wname  wnumGamesPlayed       woEff  \\\n",
       "63                2  98.529129        Syracuse               29  112.749541   \n",
       "127               3  89.885700     Connecticut               33  111.097074   \n",
       "191               2  91.615572  North Carolina               31  115.602174   \n",
       "255               4  95.169808         Florida               33  116.501456   \n",
       "319               4  92.638035         Florida               34  119.599871   \n",
       "383               4  88.485578          Kansas               33  116.404478   \n",
       "447               2  96.797445  North Carolina               31  118.741033   \n",
       "511               4  91.111407            Duke               34  115.043575   \n",
       "578               5  99.982906     Connecticut               35  110.543668   \n",
       "645               3  86.961502        Kentucky               34  112.715253   \n",
       "712               4  86.112925      Louisville               34  109.252751   \n",
       "779               2  97.159181     Connecticut               34  110.555255   \n",
       "846               2  99.294094            Duke               33  121.892002   \n",
       "913               3  95.410072       Villanova               34  115.004811   \n",
       "980               2  97.232471  North Carolina               33  115.555253   \n",
       "\n",
       "     wwinsVsTourney  chipGame  \n",
       "63                5      True  \n",
       "127               8      True  \n",
       "191               8      True  \n",
       "255               7      True  \n",
       "319               8      True  \n",
       "383               8      True  \n",
       "447               6      True  \n",
       "511               8      True  \n",
       "578              12      True  \n",
       "645              11      True  \n",
       "712              11      True  \n",
       "779               7      True  \n",
       "846              10      True  \n",
       "913              10      True  \n",
       "980              10      True  \n",
       "\n",
       "[15 rows x 39 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchups = findChampionshipMatches()\n",
    "matchups[matchups[\"chipGame\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionsChips():\n",
    "    \"\"\"\n",
    "    Outputs predictions for all championship games from 2003-2017 using a Random Forest classifier. Baseline model takes team with lower RPI as winner. \n",
    "    Returns a tuple consisting of a data frame containing the model's prediction for every matchup in our test dataset, the baseline model's accuracy, our model's accuracy\n",
    "    \"\"\"\n",
    "    matchups = findChampionshipMatches()\n",
    "    matchups[\"baseline\"] = matchups[\"wRPI\"] < matchups[\"lRPI\"]\n",
    "    cols = list(matchups.columns)\n",
    "\n",
    "    train = matchups[matchups[\"chipGame\"] == False]\n",
    "    test = matchups[matchups[\"chipGame\"] == True]\n",
    "    baselineAcc = 1.0*sum(test[\"baseline\"]) / test.shape[0]\n",
    "    \n",
    "    trainLabels = np.array(train[\"baseline\"])\n",
    "    testLabels = np.array(test[\"baseline\"])\n",
    "    testNames = np.column_stack((test[\"lname\"], test[\"l_id\"], test[\"wname\"], test[\"w_id\"]))\n",
    "    # Drop qualitative & output columns\n",
    "    train = train.drop([\"w_id\", \"l_id\", \"baseline\", \"wname\", \"lname\", \"season\", \"dayNum\", \"chipGame\"], axis = 1)\n",
    "    test = test.drop([\"w_id\", \"l_id\", \"baseline\", \"wname\", \"lname\", \"season\", \"dayNum\", \"chipGame\"], axis = 1)\n",
    "    feature_names = train.columns\n",
    "    trainFeatures = np.array(train)\n",
    "    testFeatures = np.array(test)\n",
    "    maxFeatures = int(len(feature_names)**0.5)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state=42, oob_score=True, max_features=maxFeatures)\n",
    "    rf.fit(trainFeatures, trainLabels)\n",
    "    ## Draw sample classification tree\n",
    "    # drawTree(rf, \"sampleTree\")\n",
    "\n",
    "    predictions = rf.predict(testFeatures)\n",
    "    predictProbs = rf.predict_proba(testFeatures)\n",
    "    modelAcc = 1.0*sum(~(predictions ^ testLabels)) / predictions.shape[0]\n",
    "    stack = np.column_stack((predictions.T, testLabels.T, testNames[:,0], testNames[:,1], testNames[:,2], testNames[:,3], predictProbs[:,0], predictProbs[:,1]))\n",
    "    return stack[stack[:,0].argsort()], baselineAcc, modelAcc\n",
    "\n",
    "### Utilize historical matchup data to build RF model. \n",
    "def getPredictions(year, train=None, test=None):\n",
    "    \"\"\"\n",
    "    Outputs predictions for games from test data set using a Random Forest classifier. Baseline model takes team with lower RPI as winner. \n",
    "    Returns a tuple consisting of a data frame containing the model's prediction for every matchup in our test dataset, the baseline model's accuracy, our model's accuracy\n",
    "    \"\"\"\n",
    "    matchups = getMatchupData()\n",
    "    matchups[\"baseline\"] = matchups[\"wRPI\"] < matchups[\"lRPI\"]\n",
    "    cols = list(matchups.columns)\n",
    "    train = matchups[~matchups[\"w_id\"].str.contains(year)]\n",
    "    test = matchups[matchups[\"w_id\"].str.contains(year)]\n",
    "    baselineAcc = 1.0*sum(test[\"baseline\"]) / test.shape[0]\n",
    "    \n",
    "    trainLabels = np.array(train[\"baseline\"])\n",
    "    testLabels = np.array(test[\"baseline\"])\n",
    "    testNames = np.column_stack((test[\"lname\"], test[\"l_id\"], test[\"wname\"], test[\"w_id\"]))\n",
    "    # Drop qualitative & output columns\n",
    "    train = train.drop([\"w_id\", \"l_id\", \"baseline\", \"wname\", \"lname\", \"season\", \"dayNum\"], axis = 1)\n",
    "    test = test.drop([\"w_id\", \"l_id\", \"baseline\", \"wname\", \"lname\", \"season\", \"dayNum\"], axis = 1)\n",
    "    feature_names = train.columns\n",
    "    trainFeatures = np.array(train)\n",
    "    testFeatures = np.array(test)\n",
    "    maxFeatures = int(len(feature_names)**0.5)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state=42, oob_score=True, max_features=maxFeatures)\n",
    "    rf.fit(trainFeatures, trainLabels)\n",
    "\n",
    "    predictions = rf.predict(testFeatures)\n",
    "    predictProbs = rf.predict_proba(testFeatures)\n",
    "    modelAcc = 1.0*sum(~(predictions ^ testLabels)) / predictions.shape[0]\n",
    "    stack = np.column_stack((predictions.T, testLabels.T, testNames[:,0], testNames[:,1], testNames[:,2], testNames[:,3], predictProbs[:,0], predictProbs[:,1]))\n",
    "    return stack[stack[:,0].argsort()], baselineAcc, modelAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTree(rf, treeName):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(rf.estimators_[0], out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names=feature_names)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    graph.write_pdf(\"{}.pdf\".format(treeName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.53\n",
      "Our Model's Accuracy: 0.93\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predict</td>\n",
       "      <td>Actual</td>\n",
       "      <td>L Name</td>\n",
       "      <td>L ID</td>\n",
       "      <td>W Name</td>\n",
       "      <td>W ID</td>\n",
       "      <td>Prob For</td>\n",
       "      <td>Prob Against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1242_2003</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>1393_2003</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1228_2005</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1314_2005</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ohio St</td>\n",
       "      <td>1326_2007</td>\n",
       "      <td>Florida</td>\n",
       "      <td>1196_2007</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>1272_2008</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1242_2008</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1246_2014</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1163_2014</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1458_2015</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1181_2015</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>1210_2004</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1163_2004</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>1417_2006</td>\n",
       "      <td>Florida</td>\n",
       "      <td>1196_2006</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Michigan St</td>\n",
       "      <td>1277_2009</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1314_2009</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Butler</td>\n",
       "      <td>1139_2010</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1181_2010</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Butler</td>\n",
       "      <td>1139_2011</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1163_2011</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1242_2012</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1246_2012</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>1276_2013</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>1257_2013</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1314_2016</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>1437_2016</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>1211_2017</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1314_2017</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1               2          3               4          5  \\\n",
       "0   Predict  Actual          L Name       L ID          W Name       W ID   \n",
       "1     False   False          Kansas  1242_2003        Syracuse  1393_2003   \n",
       "2     False   False        Illinois  1228_2005  North Carolina  1314_2005   \n",
       "3     False   False         Ohio St  1326_2007         Florida  1196_2007   \n",
       "4     False   False         Memphis  1272_2008          Kansas  1242_2008   \n",
       "5     False   False        Kentucky  1246_2014     Connecticut  1163_2014   \n",
       "6     False   False       Wisconsin  1458_2015            Duke  1181_2015   \n",
       "7      True    True    Georgia Tech  1210_2004     Connecticut  1163_2004   \n",
       "8      True   False            UCLA  1417_2006         Florida  1196_2006   \n",
       "9      True    True     Michigan St  1277_2009  North Carolina  1314_2009   \n",
       "10     True    True          Butler  1139_2010            Duke  1181_2010   \n",
       "11     True    True          Butler  1139_2011     Connecticut  1163_2011   \n",
       "12     True    True          Kansas  1242_2012        Kentucky  1246_2012   \n",
       "13     True    True        Michigan  1276_2013      Louisville  1257_2013   \n",
       "14     True    True  North Carolina  1314_2016       Villanova  1437_2016   \n",
       "15     True    True         Gonzaga  1211_2017  North Carolina  1314_2017   \n",
       "\n",
       "           6             7  \n",
       "0   Prob For  Prob Against  \n",
       "1      0.688         0.312  \n",
       "2      0.585         0.415  \n",
       "3      0.642         0.358  \n",
       "4      0.632         0.368  \n",
       "5      0.549         0.451  \n",
       "6      0.534         0.466  \n",
       "7      0.379         0.621  \n",
       "8      0.402         0.598  \n",
       "9      0.336         0.664  \n",
       "10     0.108         0.892  \n",
       "11     0.052         0.948  \n",
       "12     0.333         0.667  \n",
       "13     0.225         0.775  \n",
       "14     0.476         0.524  \n",
       "15     0.359         0.641  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indPredicts = [[\"Predict\", \"Actual\", \"L Name\", \"L ID\", \"W Name\", \"W ID\", \"Prob For\", \"Prob Against\"]]\n",
    "baseAccs = []\n",
    "modelAccs = []\n",
    "\n",
    "# Chip games testing\n",
    "outputPreds, baselineAcc, modelAcc = getPredictionsChips()\n",
    "print(\"Baseline Model Accuracy: {}\".format(round(baselineAcc, 2)))\n",
    "print(\"Our Model's Accuracy: {}\".format(round(modelAcc, 2)))\n",
    "for row in output:\n",
    "    indPredicts.append(row.tolist())\n",
    "predsDF = pd.DataFrame(indPredicts)\n",
    "predsDF\n",
    "# pd.DataFrame(indPredicts).to_csv(\"data/output/chipTestResults.csv\", index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "indPredicts = [[\"Predict\", \"Actual\", \"L Name\", \"L ID\", \"W Name\", \"W ID\", \"Prob For\", \"Prob Against\"]]\n",
    "baseAccs = []\n",
    "modelAccs = []\n",
    "for i in range(2003, 2018):\n",
    "    outputPreds, baselineAcc, modelAcc = getPredictions(str(i))\n",
    "    baseAccs.append(round(baselineAcc, 2))\n",
    "    modelAccs.append(round(modelAcc, 2))\n",
    "    for row in outputPreds:\n",
    "        indPredicts.append(row.tolist())\n",
    "        \n",
    "# pd.DataFrame(indPredicts).to_csv(\"data/output/testResults.csv\", index=False, header=False)\n",
    "accDF = pd.DataFrame({\"Season\": range(2003,2018), \"Baseline\": baseAccs, \"RF\": modelAccs})\n",
    "predsDF = pd.DataFrame(indPredicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predict</td>\n",
       "      <td>Actual</td>\n",
       "      <td>L Name</td>\n",
       "      <td>L ID</td>\n",
       "      <td>W Name</td>\n",
       "      <td>W ID</td>\n",
       "      <td>Prob For</td>\n",
       "      <td>Prob Against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1242_2003</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>1393_2003</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1400_2003</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>1393_2003</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>1448_2003</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>1120_2003</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>1257_2003</td>\n",
       "      <td>Butler</td>\n",
       "      <td>1139_2003</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1            2          3         4          5         6  \\\n",
       "0  Predict  Actual       L Name       L ID    W Name       W ID  Prob For   \n",
       "1    False   False       Kansas  1242_2003  Syracuse  1393_2003     0.521   \n",
       "2    False   False        Texas  1400_2003  Syracuse  1393_2003     0.514   \n",
       "3    False   False  Wake Forest  1448_2003    Auburn  1120_2003     0.904   \n",
       "4    False   False   Louisville  1257_2003    Butler  1139_2003     0.853   \n",
       "\n",
       "              7  \n",
       "0  Prob Against  \n",
       "1         0.479  \n",
       "2         0.486  \n",
       "3         0.096  \n",
       "4         0.147  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Baseline    RF\n",
       "0     2003      0.70  1.00\n",
       "1     2004      0.73  0.95\n",
       "2     2005      0.73  0.98\n",
       "3     2006      0.64  0.94\n",
       "4     2007      0.73  0.95\n",
       "5     2008      0.73  0.97\n",
       "6     2009      0.73  0.94\n",
       "7     2010      0.69  0.92\n",
       "8     2011      0.63  0.99\n",
       "9     2012      0.66  0.93\n",
       "10    2013      0.64  0.90\n",
       "11    2014      0.64  0.91\n",
       "12    2015      0.73  0.94\n",
       "13    2016      0.70  0.93\n",
       "14    2017      0.72  0.91"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
