{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Summary\n",
    "\n",
    "The goal from this analysis will be to predict the outcome of March Madness games. To do this, I will look at historical data from NCAA tourney matchups from 2003 up to 2018 output predictions for the winning team for each game. For every March Madness game, each team will be assigned a score based on its regular season performance in  several statistical categories, assigned rankings, and how well its oppponent performs in several statistical categories. \n",
    "\n",
    "### Baseline Models\n",
    "I will be using a few baseline models to compare the model's results against. The baseline models I will be using are:\n",
    "\n",
    "    - March Madness Seed: The seed assigned to each team for a March Madness tournament\n",
    "    - Rating Percentage Index (RPI):  Ranking assigned to each team based on a team's wins, losses, and strength of record\n",
    "    - Pomeroy College Basketball Ratings (POM): Ken Pomeroy's annual college basketball ratings \n",
    "\n",
    "The baseline models pose the following hypothesis:\n",
    "\n",
    "    - That in any NCAA tournament game, the winner of a game will have either a lower March Madness seed, lower RPI, or lower POM rating.\n",
    "  \n",
    "Intuitively, this is a reasonable prediction. RPI, March Madness seeds, and POM ratings are all based on a team's wins, losses, strength of schedule, and generally considered representative of a team's performance relative to other teams. If team A has a lower RPI than team B at the end of a season, it's generally considered that team A's performance throughout the season has been at a higher level than team B's. For this reason, if we knew nothing else about the two teams, predicting the outcome based on RPI, or the other two benchmarks, is a good starting point. \n",
    "\n",
    "### Data Sources Overview\n",
    "The data that was used to perform this analysis came from the [Google Cloud & NCAAÂ® ML Competition 2018-Men's Kaggle competition](https://www.kaggle.com/c/mens-machine-learning-competition-2018). The following is a brief summary of all the datasets that were used:\n",
    "- NCAATourneyCompactResults: Contains records from each NCAA tournament game from 1985-2017, including score and region.  \n",
    "- Teams: Contains information for each Division 1 (D1) basketball team including an ID, name, first and most recent year playing D1 basketball. \n",
    "- MasseyOrdinals_Prelim2018: Contains data from 2003-2017 surrounding each D1 team's rank from various rankings sources throughout. \n",
    "- RegularSeasonDetailedResults: Contains similar information as the NCAATourneyCompactResults dataset, with the addition that each row will also contain the totals in a variety of statistical categories for the winning team and losing team. These are categories that are often found in a boxscore. \n",
    "\n",
    "A more in depth description of each of the datasets that were used and additional datasets provided by Kaggle can be found at https://www.kaggle.com/c/mens-machine-learning-competition-2018/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing & Preparation\n",
    "\n",
    "In order for the model to be created, the following was completed:\n",
    "    1. A data frame was created that holds a set of statistics for each team in a given year used to evaluate the that team's offensive and defensive performance. \n",
    "    2. A data frame was created, where each row represents a matchup that occurred in an NCAA tournament and contains the set of statistics for each team in the matchup \n",
    "\n",
    "To accomplish the first task, the following statistics were calculated for each team:\n",
    "    - Three Point Percentage (3P%)\n",
    "    - Two Point Percentage (2P%)\n",
    "    - Defensive Rebounds (DR)\n",
    "    - Offensive Rebounds (OR)\n",
    "    - Field Goal Percentage (FG%)\n",
    "    - Free Throws Attempted (FTA)\n",
    "    - Free Throw Percentage (FTP)\n",
    "    - Turnovers (TO)\n",
    "    - Turnovers Forced (TOF)\n",
    "    - Personal Fouls (PF)\n",
    "    - Efficient Field Goal Percentage (eFG): (FGM + 0.5 * 3PM) / FGA\n",
    "    - Possessions (POS): FGA - ORB + TO + (0.4 x FTA)\n",
    "    - Defensive Efficiency (dEff): 100 x PA / (FGA - ORB + TO + (0.4 x FTA))   \n",
    "    - Offensive Effiency (oEff): 100 x (PS) / (FGA - ORB + TO + (0.4 x FTA))\n",
    "    - Three Point Usage (3PP): 3PA / FGA\n",
    "    - Two Point Usage (2PP): 2PA / FGA\n",
    "    - Rankings Percentage Index (RPI)\n",
    "    - March Madness Seed (Seed)\n",
    "    - Ken Pomeroy Rating (POM)\n",
    "\n",
    "Each statistic was calcualated using game data leading up to the tournament, including conference play. RPI, March Madness Seed, and POM ratings were found using the latest ranking given to a team before the tournament.\n",
    "\n",
    "An example of the output data frame is seen below with a snapshot of some teams' performance in 2003:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamId</th>\n",
       "      <th>oEff</th>\n",
       "      <th>dEff</th>\n",
       "      <th>eFG</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>3PP</th>\n",
       "      <th>2P%</th>\n",
       "      <th>2PP</th>\n",
       "      <th>FTA</th>\n",
       "      <th>OR</th>\n",
       "      <th>DR</th>\n",
       "      <th>TO</th>\n",
       "      <th>TOF</th>\n",
       "      <th>POS</th>\n",
       "      <th>PF</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102_2003</td>\n",
       "      <td>1.062575</td>\n",
       "      <td>1.057935</td>\n",
       "      <td>0.678187</td>\n",
       "      <td>0.481149</td>\n",
       "      <td>0.375643</td>\n",
       "      <td>0.651357</td>\n",
       "      <td>0.409857</td>\n",
       "      <td>0.596987</td>\n",
       "      <td>0.590143</td>\n",
       "      <td>17.107143</td>\n",
       "      <td>4.178571</td>\n",
       "      <td>16.821429</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>12.964286</td>\n",
       "      <td>53.878571</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103_2003</td>\n",
       "      <td>1.140972</td>\n",
       "      <td>1.131853</td>\n",
       "      <td>0.583886</td>\n",
       "      <td>0.486074</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.736390</td>\n",
       "      <td>0.207334</td>\n",
       "      <td>0.545624</td>\n",
       "      <td>0.792666</td>\n",
       "      <td>25.851852</td>\n",
       "      <td>9.777778</td>\n",
       "      <td>19.925926</td>\n",
       "      <td>12.629630</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>69.044444</td>\n",
       "      <td>19.851852</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1104_2003</td>\n",
       "      <td>1.061618</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.531855</td>\n",
       "      <td>0.420362</td>\n",
       "      <td>0.320144</td>\n",
       "      <td>0.709898</td>\n",
       "      <td>0.275258</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>20.928571</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>23.928571</td>\n",
       "      <td>13.285714</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>65.264286</td>\n",
       "      <td>18.035714</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105_2003</td>\n",
       "      <td>0.950489</td>\n",
       "      <td>1.015179</td>\n",
       "      <td>0.519039</td>\n",
       "      <td>0.395755</td>\n",
       "      <td>0.364815</td>\n",
       "      <td>0.705986</td>\n",
       "      <td>0.316720</td>\n",
       "      <td>0.411488</td>\n",
       "      <td>0.683280</td>\n",
       "      <td>21.846154</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>23.115385</td>\n",
       "      <td>18.653846</td>\n",
       "      <td>18.807692</td>\n",
       "      <td>75.507692</td>\n",
       "      <td>20.230769</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1106_2003</td>\n",
       "      <td>0.954755</td>\n",
       "      <td>0.956899</td>\n",
       "      <td>0.534561</td>\n",
       "      <td>0.423773</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.646421</td>\n",
       "      <td>0.288040</td>\n",
       "      <td>0.460152</td>\n",
       "      <td>0.711960</td>\n",
       "      <td>16.464286</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>17.035714</td>\n",
       "      <td>15.071429</td>\n",
       "      <td>66.621429</td>\n",
       "      <td>18.178571</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      teamId      oEff      dEff       eFG       FG%       3P%       FT%  \\\n",
       "0  1102_2003  1.062575  1.057935  0.678187  0.481149  0.375643  0.651357   \n",
       "1  1103_2003  1.140972  1.131853  0.583886  0.486074  0.338710  0.736390   \n",
       "2  1104_2003  1.061618  0.995951  0.531855  0.420362  0.320144  0.709898   \n",
       "3  1105_2003  0.950489  1.015179  0.519039  0.395755  0.364815  0.705986   \n",
       "4  1106_2003  0.954755  0.956899  0.534561  0.423773  0.346154  0.646421   \n",
       "\n",
       "        3PP       2P%       2PP        FTA         OR         DR         TO  \\\n",
       "0  0.409857  0.596987  0.590143  17.107143   4.178571  16.821429  11.428571   \n",
       "1  0.207334  0.545624  0.792666  25.851852   9.777778  19.925926  12.629630   \n",
       "2  0.275258  0.473684  0.724742  20.928571  13.571429  23.928571  13.285714   \n",
       "3  0.316720  0.411488  0.683280  21.846154  13.500000  23.115385  18.653846   \n",
       "4  0.288040  0.460152  0.711960  16.464286  12.285714  23.857143  17.035714   \n",
       "\n",
       "         TOF        POS         PF season  \n",
       "0  12.964286  53.878571  18.750000   2003  \n",
       "1  15.333333  69.044444  19.851852   2003  \n",
       "2  13.857143  65.264286  18.035714   2003  \n",
       "3  18.807692  75.507692  20.230769   2003  \n",
       "4  15.071429  66.621429  18.178571   2003  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsDemo = setupStatsDF(2003)\n",
    "statsDemo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the second requirement of preparing the data for the model, two steps were taken: \n",
    "1. The data frame that was created above and a data frame holding the rankings for all teams by year were merged based on a shared custom id. The custom id was a combination of a team's id and the season the corresponding row of data was associated to. \n",
    "2. The merged data frame's features were normalized, converting all values to a scale from 0 - 1. The features were normalized for two reasons: \n",
    "    1. To allow each record of data to be interpreted the same way\n",
    "    2. Eliminate any additional influence a feature with a large range (FTA) would have compared to a feature with a smaller range of data (FT%). \n",
    "\n",
    "The output of these two steps can be seen below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamId</th>\n",
       "      <th>oEff</th>\n",
       "      <th>dEff</th>\n",
       "      <th>eFG</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>3PP</th>\n",
       "      <th>2P%</th>\n",
       "      <th>2PP</th>\n",
       "      <th>...</th>\n",
       "      <th>OR</th>\n",
       "      <th>DR</th>\n",
       "      <th>TO</th>\n",
       "      <th>TOF</th>\n",
       "      <th>POS</th>\n",
       "      <th>PF</th>\n",
       "      <th>season</th>\n",
       "      <th>Seed</th>\n",
       "      <th>POM</th>\n",
       "      <th>RPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1104_2003</td>\n",
       "      <td>0.240034</td>\n",
       "      <td>0.441460</td>\n",
       "      <td>0.081066</td>\n",
       "      <td>0.160056</td>\n",
       "      <td>0.024833</td>\n",
       "      <td>0.540265</td>\n",
       "      <td>0.517317</td>\n",
       "      <td>0.273052</td>\n",
       "      <td>0.482683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687804</td>\n",
       "      <td>0.467720</td>\n",
       "      <td>0.317239</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.342766</td>\n",
       "      <td>0.409248</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.171296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1112_2003</td>\n",
       "      <td>0.669673</td>\n",
       "      <td>0.187895</td>\n",
       "      <td>0.386234</td>\n",
       "      <td>0.559339</td>\n",
       "      <td>0.347937</td>\n",
       "      <td>0.489395</td>\n",
       "      <td>0.395750</td>\n",
       "      <td>0.538274</td>\n",
       "      <td>0.604250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880254</td>\n",
       "      <td>0.957187</td>\n",
       "      <td>0.482932</td>\n",
       "      <td>0.757805</td>\n",
       "      <td>0.954239</td>\n",
       "      <td>0.372801</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1113_2003</td>\n",
       "      <td>0.613722</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>0.221122</td>\n",
       "      <td>0.722442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.386250</td>\n",
       "      <td>0.396140</td>\n",
       "      <td>0.598082</td>\n",
       "      <td>0.490229</td>\n",
       "      <td>0.585044</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.143519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1120_2003</td>\n",
       "      <td>0.188074</td>\n",
       "      <td>0.397887</td>\n",
       "      <td>0.422431</td>\n",
       "      <td>0.641261</td>\n",
       "      <td>0.288017</td>\n",
       "      <td>0.253537</td>\n",
       "      <td>0.366593</td>\n",
       "      <td>0.631687</td>\n",
       "      <td>0.633407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491648</td>\n",
       "      <td>0.288249</td>\n",
       "      <td>0.606018</td>\n",
       "      <td>0.631788</td>\n",
       "      <td>0.421546</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.162037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1122_2003</td>\n",
       "      <td>0.179950</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.379396</td>\n",
       "      <td>0.471159</td>\n",
       "      <td>0.333096</td>\n",
       "      <td>0.428905</td>\n",
       "      <td>0.442242</td>\n",
       "      <td>0.487484</td>\n",
       "      <td>0.557758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335534</td>\n",
       "      <td>0.506417</td>\n",
       "      <td>0.531149</td>\n",
       "      <td>0.417219</td>\n",
       "      <td>0.403711</td>\n",
       "      <td>0.489736</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.448529</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      teamId      oEff      dEff       eFG       FG%       3P%       FT%  \\\n",
       "0  1104_2003  0.240034  0.441460  0.081066  0.160056  0.024833  0.540265   \n",
       "1  1112_2003  0.669673  0.187895  0.386234  0.559339  0.347937  0.489395   \n",
       "2  1113_2003  0.613722  0.545460  0.221122  0.722442  0.000000  0.299035   \n",
       "3  1120_2003  0.188074  0.397887  0.422431  0.641261  0.288017  0.253537   \n",
       "4  1122_2003  0.179950  0.544580  0.379396  0.471159  0.333096  0.428905   \n",
       "\n",
       "        3PP       2P%       2PP    ...           OR        DR        TO  \\\n",
       "0  0.517317  0.273052  0.482683    ...     0.687804  0.467720  0.317239   \n",
       "1  0.395750  0.538274  0.604250    ...     0.880254  0.957187  0.482932   \n",
       "2  0.000000  0.636862  1.000000    ...     0.701961  0.386250  0.396140   \n",
       "3  0.366593  0.631687  0.633407    ...     0.491648  0.288249  0.606018   \n",
       "4  0.442242  0.487484  0.557758    ...     0.335534  0.506417  0.531149   \n",
       "\n",
       "        TOF       POS        PF  season Seed       POM       RPI  \n",
       "0  0.400189  0.342766  0.409248    2003  0.6  0.117647  0.171296  \n",
       "1  0.757805  0.954239  0.372801    2003  0.0  0.007353  0.004630  \n",
       "2  0.598082  0.490229  0.585044    2003  0.6  0.113971  0.143519  \n",
       "3  0.631788  0.421546  0.196334    2003  0.6  0.161765  0.162037  \n",
       "4  0.417219  0.403711  0.489736    2003  0.8  0.448529  0.333333  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = getRankings()\n",
    "seeds = getSeeds()\n",
    "seedsAndRanks = mergeSeedsAndRanks(seeds, ranks)\n",
    "statsSeeds = mergeSeedsRanksStats(seedsAndRanks, statsDemo)\n",
    "normStats = normalizeFeatures(statsSeeds)\n",
    "normStats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation & Score Assignment\n",
    "\n",
    "Using the normalized statistics data frame and a data frame consisting of historical records of each March Madness tournament matchup, a score can be calculated for each team to predict the outcome of a tournament game. Each team is given a score based on several criteria:\n",
    "\n",
    "- Offensive Performance Score\n",
    "- Defensive Performance Score:\n",
    "- External Ranking Score: \n",
    "\n",
    "\n",
    "\n",
    "Lastly, each matchup was analyzed to assign a score to each team based on offensive performance, defensive performance, and external rankings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchDemo = createModelMatchupsDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from scipy import stats as sciStats\n",
    "import numpy as np\n",
    "import team, game as g\n",
    "import Model as mod\n",
    "\n",
    "\"\"\"\n",
    "stats for each team found from a certain year \n",
    "seeds and rankings are found for each team from a certain year \n",
    "data frames are merged linking stats to seeds/ranks\n",
    "merged data frame is normalized to give all stats or ranks equal weight\n",
    "\n",
    "each matchup from a year's tournament is used to calculate a score for each team\n",
    "score is calculated using the normalized features and the logic in the findScore function\n",
    "- Offensive score, defensive score, ranking score that are combined \n",
    "- weights used were based on four factors of basketball and then adjusted \n",
    "\n",
    "score for both team is calculated and then used to create a new data frame for the corresponding matchup \n",
    "a score for both teams in each matchup is calculated and a data frame with those scores is created \n",
    "A prediction for each matchup in data frame is found by looking at which team has highest calculated score \n",
    "\n",
    "model predictions are compared against baseline models based on how many games were picked accurately by year \n",
    "one tailed proportions test was done to test whether or not the models results were significant \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTeamNames():\n",
    "    \"\"\"\n",
    "    Return dictionary where key is team ID and value is team name\n",
    "    \"\"\"\n",
    "    names = {}\n",
    "    teams = pd.read_csv(\"Data/Teams.csv\")\n",
    "    for index, row in teams.iterrows():\n",
    "        teamId = row[\"TeamID\"]\n",
    "        name = row[\"TeamName\"]\n",
    "        names[teamId] = name\n",
    "    return names\n",
    "\n",
    "def getSeasonStats(ncaaTourneyTeams):\n",
    "    \"\"\"\n",
    "    Use regular season results and RPI rankings to create a \n",
    "    dictionary where key is the team's ID and the value is a \n",
    "    Team object. Team objects contain yearly avg stats for each \n",
    "    team in various categories.\n",
    "    \"\"\"\n",
    "    teams = {}\n",
    "    names = getTeamNames()\n",
    "    unfiltRanks = pd.read_csv(\"data/MasseyOrdinals_Prelim2018.csv\")\n",
    "    rankings = unfiltRanks[(unfiltRanks[\"SystemName\"] == \"RPI\") & (unfiltRanks[\"RankingDayNum\"] == 133)]\n",
    "    regSeasonResults = pd.read_csv(\"data/RegularSeasonDetailedResults.csv\")\n",
    "    for index, row in regSeasonResults.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "        wRPI = None\n",
    "        lRPI = None\n",
    "        try:\n",
    "            wRPI = rankings[(rankings[\"Season\"] == season) & (rankings[\"TeamID\"] == wTeamId)].iloc[0][\"OrdinalRank\"]\n",
    "            lRPI = rankings[(rankings[\"Season\"] == season) & (rankings[\"TeamID\"] == lTeamId)].iloc[0][\"OrdinalRank\"]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print str(lTeamId) + \" \" + str(season) + \" not found\"\n",
    "        \n",
    "        if customWId not in teams:\n",
    "            teams[customWId] = team.Team(customWId)\n",
    "        if customLId not in teams:\n",
    "            teams[customLId] = team.Team(customLId)\n",
    "        wTeam = teams[customWId]\n",
    "        wTeam.RPI = wRPI\n",
    "        wTeam.name = names[wTeamId]\n",
    "        wTeam.updateStats(row, True)\n",
    "        if customLId in ncaaTourneyTeams:\n",
    "            wTeam.winsVsTourney += 1\n",
    "        lTeam = teams[customLId]\n",
    "        lTeam.name = names[lTeamId]\n",
    "        lTeam.RPI = lRPI\n",
    "        lTeam.updateStats(row, False)\n",
    "        \n",
    "    for t in teams:\n",
    "        teams[t].setScore()\n",
    "    \n",
    "    return teams\n",
    "\n",
    "def getTeamStats(teams):\n",
    "    \"\"\"\n",
    "    Get season stats for each team in a Data Frame. Able to see yearly averages and totals for stored\n",
    "    statistical categories in each team object in teams dictionary\n",
    "    \"\"\"\n",
    "    allTeamData = []\n",
    "    visited = set()\n",
    "    for team in teams:\n",
    "        if team not in visited:\n",
    "            idAndSeason = team.split(\"_\")\n",
    "            season = idAndSeason[1]\n",
    "            _id = idAndSeason[0]\n",
    "            teamData = teams[team].objToDict()\n",
    "            teamData['season'] = season\n",
    "            allTeamData.append(teamData)\n",
    "            visited.add(team)\n",
    "    return pd.DataFrame(allTeamData)\n",
    "\n",
    "def dataToDict(df):\n",
    "    \"\"\"\n",
    "    Convert dataframe to list to dictionary where key is team id and value is row data\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for index, row in df.iterrows():\n",
    "        data[row[\"_id\"]] = row.to_dict()\n",
    "    return data\n",
    "\n",
    "def normalizeFeatures(teamStats):\n",
    "    \"\"\"\n",
    "    Uses team stats for all seasons and returns data frame with stats normalized by season\n",
    "    \"\"\"\n",
    "    toReturn = teamStats.copy()\n",
    "    copy = toReturn.copy()\n",
    "    copy['season'] = copy['season'].astype(int)\n",
    "    copy.drop(copy.select_dtypes(['object']), inplace=True, axis=1)\n",
    "    normalized = normalize(copy, 'season')\n",
    "#     normalized.drop(columns=['numGamesPlayed'])\n",
    "    toReturn.update(normalized)\n",
    "    return toReturn\n",
    "\n",
    "def normalize(df, by):\n",
    "    \"\"\"\n",
    "    groups df by season and normalizes each statistical category of features from 0 - 1\n",
    "    \"\"\"\n",
    "    groups = df.groupby(by)\n",
    "    mins = groups.transform(np.min)\n",
    "    maxs = groups.transform(np.max)\n",
    "    return (df[mins.columns] - mins) / (maxs - mins)\n",
    "\n",
    "def populateNCAATourneyTeams():\n",
    "    \"\"\"\n",
    "    Create an ID for each team using a combination of its id and the season the team played in. \n",
    "    Output a dictionary with an entry for each team whose key is its newly created id\n",
    "    \"\"\"\n",
    "    ncaaTourneyTeams = {}\n",
    "    ncaaTournResults = pd.read_csv(\"data/NCAATourneyCompactResults.csv\")\n",
    "    for index, row in ncaaTournResults.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "\n",
    "        if customWId not in ncaaTourneyTeams:\n",
    "            ncaaTourneyTeams[customWId] = 1\n",
    "        if customLId not in ncaaTourneyTeams:\n",
    "            ncaaTourneyTeams[customLId] = 1\n",
    "    return ncaaTourneyTeams\n",
    "\n",
    "def getMatchups(teams, inputDataModified=False):\n",
    "    \"\"\"\n",
    "    Use NCAA Tournament results to return data frame of matchups where each row contains data for one matchup between two teams, including their yearly avg totals in statistical categories, RPI, and game result.\n",
    "    \"\"\"\n",
    "    matchups = []\n",
    "    ncaaTournResults = pd.read_csv(\"data/NCAATourneyCompactResults.csv\")\n",
    "    for index, row in ncaaTournResults.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "\n",
    "        if customWId in teams and customLId in teams:\n",
    "            wTeamData, lTeamData = {}, {}\n",
    "            if inputDataModified:\n",
    "                wTeamData = teams[customWId].copy()\n",
    "                del wTeamData['season']\n",
    "            else:\n",
    "                wTeamData = teams[customWId].objToDict().copy()\n",
    "            wTeamDataMod, lTeamDataMod = {}, {}\n",
    "            for key in wTeamData.keys():\n",
    "                wTeamDataMod[\"w\" + key] = wTeamData[key]\n",
    "                \n",
    "            if inputDataModified:\n",
    "                lTeamData = teams[customLId]\n",
    "                del lTeamData['season']\n",
    "            else:\n",
    "                lTeamData = teams[customLId].objToDict().copy()\n",
    "            for key in lTeamData.keys():\n",
    "                lTeamDataMod[\"l\" + key] = lTeamData[key]\n",
    "                \n",
    "            matchupData = wTeamDataMod.copy()\n",
    "            matchupData.update(lTeamDataMod)\n",
    "            matchupData[\"dayNum\"] = dayNum\n",
    "            matchupData[\"season\"] = season\n",
    "            matchups.append(matchupData)\n",
    "    colOrder = [\"dayNum\", \"season\", \"l_id\", \"lname\", \"w_id\", \"wname\", \"lscore\", \"wscore\", \"lDRB\", \"lEFG\", \"lFTA\", \"lFTP\", \"lMOL\", \"lMOV\", \"lORB\", \"lPOSS\",\n",
    "                \"lRPI\", \"lTO\", \"lTOF\", \"lconfTournWins\", \"ldEff\", \"lnumGamesPlayed\", \"loEff\", \"lwinsVsTourney\",\n",
    "                \"wDRB\", \"wEFG\", \"wFTA\", \"wFTP\", \"wMOL\", \"wMOV\", \"wORB\", \"wPOSS\", \"wRPI\", \"wTO\", \"wTOF\", \n",
    "                \"wconfTournWins\", \"wdEff\", \"wnumGamesPlayed\", \"woEff\", \"wwinsVsTourney\"]\n",
    "    df = pd.DataFrame.from_dict(matchups)\n",
    "    df = df[colOrder]\n",
    "    return df\n",
    "\n",
    "def getMatchupData():\n",
    "    \"\"\"\n",
    "    Returns data frame of historical matchups in NCAA tournament.\n",
    "    Reads in existing CSV if available. Otherwise, produces data frame by creating Team objects, calculating yearly avg totals for each team, and joining with historical NCAA tourney matchup data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        matchups = pd.read_csv(\"Data/output/matchups_normalized.csv\")\n",
    "        return matchups\n",
    "    except Exception as e:\n",
    "        ncaaTourneyTeams = populateNCAATourneyTeams()\n",
    "        teamObjs = getSeasonStats(ncaaTourneyTeams)\n",
    "        teamStats = getTeamStats(teamObjs)\n",
    "        normalized = normalizeFeatures(teamStats)\n",
    "        dataAsDict = dataToDict(normalized)\n",
    "        matchups = getMatchups(dataAsDict, inputDataModified=True)\n",
    "        matchups.to_csv(\"Data/output/matchups_normalized.csv\", index=False)\n",
    "        return matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRankings():\n",
    "    unfiltRanks = pd.read_csv(\"data/MasseyOrdinals_Prelim2018.csv\")\n",
    "    rankings = unfiltRanks[(unfiltRanks[\"SystemName\"] == \"POM\") & (unfiltRanks[\"RankingDayNum\"] == 133) | (unfiltRanks[\"SystemName\"] == \"RPI\") & (unfiltRanks[\"RankingDayNum\"] == 133)]\n",
    "    transpose = {}\n",
    "    for index, row in rankings.iterrows():\n",
    "        teamId = str(row[\"TeamID\"]) + \"_\" + str(row[\"Season\"])\n",
    "        if teamId in transpose:\n",
    "            if row[\"SystemName\"] == \"RPI\":\n",
    "                transpose[teamId][\"RPI\"] = row[\"OrdinalRank\"]\n",
    "            else:\n",
    "                transpose[teamId][\"POM\"] = row[\"OrdinalRank\"]\n",
    "        else:\n",
    "            transpose[teamId] = {}\n",
    "            if row[\"SystemName\"] == \"RPI\":\n",
    "                transpose[teamId][\"RPI\"] = row[\"OrdinalRank\"]\n",
    "            else:\n",
    "                transpose[teamId][\"POM\"] = row[\"OrdinalRank\"]\n",
    "    ranksDF = pd.DataFrame.from_dict(orient = \"index\", data = transpose).reset_index()\n",
    "    ranksDF.columns = [\"teamId\", \"POM\", \"RPI\"]\n",
    "    return ranksDF\n",
    "\n",
    "def getSeeds():\n",
    "    seeds = pd.read_csv(\"data/NCAATourneySeeds.csv\")\n",
    "    seeds[\"teamId\"] = seeds.TeamID.astype(str).str.cat(seeds.Season.astype(str), sep='_')\n",
    "    seeds[\"Seed\"] = seeds.Seed.str.extract('(\\d+)', expand=False).astype(int)\n",
    "    seeds = seeds.drop([\"Season\", \"TeamID\"], axis = 1)\n",
    "    return seeds\n",
    "\n",
    "def mergeSeedsAndRanks(seeds, ranks):\n",
    "    return seeds.merge(ranks, how = \"inner\", on = \"teamId\")\n",
    "\n",
    "def mergeSeedsRanksStats(seedsAndRanks, stats):\n",
    "    return stats.merge(seedsAndRanks, how = \"inner\", on = \"teamId\")\n",
    "\n",
    "def normalizeFeatures(teamStats):\n",
    "    \"\"\"\n",
    "    Uses team stats for all seasons and returns data frame with stats normalized by season\n",
    "    \"\"\"\n",
    "    toReturn = teamStats.copy()\n",
    "    copy = toReturn.copy()\n",
    "    copy['season'] = copy['season'].astype(int)\n",
    "    copy.drop(copy.select_dtypes(['object']), inplace=True, axis=1)\n",
    "    normalized = normalize(copy, 'season')\n",
    "    toReturn.update(normalized)\n",
    "    return toReturn\n",
    "\n",
    "def normalize(df, by):\n",
    "    \"\"\"\n",
    "    groups df by season and normalizes each statistical category of features from 0 - 1\n",
    "    \"\"\"\n",
    "    groups = df.groupby(by)\n",
    "    mins = groups.transform(np.min)\n",
    "    maxs = groups.transform(np.max)\n",
    "    return (df[mins.columns] - mins) / (maxs - mins)\n",
    "\n",
    "def findScore(teamA, teamB):\n",
    "    offScoreData = [5*teamA[\"oEff\"].values[0],(1 - teamA[\"POS\"] - teamB[\"POS\"].values[0]).values[0],2*teamA[\"3PP\"].values[0],3*teamA[\"3P%\"].values[0],8*teamA[\"FG%\"].values[0],5*teamA[\"FTA\"].values[0],3.5*teamA[\"FT%\"].values[0],2*teamA[\"OR\"].values[0],2.5*teamA[\"TO\"].values[0]]\n",
    "    defScoreData = [8.5*(1-teamA[\"dEff\"]).values[0], 5*teamA[\"DR\"].values[0], 3*teamA[\"TOF\"].values[0], 5*teamA[\"PF\"].values[0]]\n",
    "    seedData = [12.5*(1-teamA[\"Seed\"]).values[0], 10*(1-teamA[\"POM\"]).values[0], 7.5*(1-teamA[\"RPI\"]).values[0]]\n",
    "    offScore = (5*teamA[\"oEff\"]*(1 - teamA[\"POS\"] - teamB[\"POS\"].values[0]) + 4*teamA[\"3P%\"] + 8*teamA[\"2P%\"] + 5*teamA[\"FTA\"] + 3.5*teamA[\"FT%\"] + 2*teamA[\"OR\"] - 2.5*teamA[\"TO\"])\n",
    "    defScore = (8.5*(1-teamA[\"dEff\"]) + 5*teamA[\"DR\"] + 3*teamA[\"TOF\"] - 5*teamA[\"PF\"])\n",
    "    seedScore = 12.5*(1-teamA[\"Seed\"]) + 10*(1-teamA[\"POM\"]) + 7.5*(1-teamA[\"RPI\"])\n",
    "    total = offScore.values[0] + defScore.values[0] + seedScore.values[0]\n",
    "    scoreData = [teamA[\"teamId\"].values[0]] + offScoreData + [offScore.values[0]] + defScoreData + [defScore.values[0]] + seedData + [seedScore.values[0]] + [total]\n",
    "    return scoreData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupStatsDF(year):\n",
    "    allGames = []\n",
    "    regSeasonResults = pd.read_csv(\"data/RegularSeasonDetailedResults.csv\")\n",
    "    games = regSeasonResults[regSeasonResults[\"Season\"] == year]\n",
    "    for index, row in games.iterrows():\n",
    "        season = row[\"Season\"]\n",
    "        dayNum = row[\"DayNum\"]\n",
    "        wTeamId = row[\"WTeamID\"]\n",
    "        lTeamId = row[\"LTeamID\"]\n",
    "        customWId = str(wTeamId) + \"_\" + str(season)\n",
    "        customLId = str(lTeamId) + \"_\" + str(season)\n",
    "        row1 = [customWId, season, dayNum, row[\"WScore\"], row[\"LScore\"], row[30]] + list(row[8:21])\n",
    "        row2 = [customLId, season, dayNum, row[\"LScore\"], row[\"WScore\"], row[17]] + list(row[21:])\n",
    "        allGames.append(row1)\n",
    "        allGames.append(row2)\n",
    "    colNames = [\"teamId\", \"season\", \"dayNum\", \"score\", \"oppScore\", \"TOF\", \"FGM\", \"FGA\", \"FGM3\", \"FGA3\", \"FTM\", \"FTA\", \"OR\", \"DR\", \"Ast\", \n",
    "               \"TO\", \"Stl\", \"Blk\", \"PF\"]\n",
    "    gamesDF = pd.DataFrame(allGames, columns = colNames)\n",
    "    gamesDF = gamesDF.drop([\"dayNum\"], axis = 1)\n",
    "    gamesDF[\"season\"] = gamesDF[\"season\"].astype(\"object\")\n",
    "    gamesDF[\"teamId\"] = gamesDF[\"teamId\"].astype(\"object\")\n",
    "    statDevs = gamesDF.groupby(by = \"teamId\").std().reset_index() ## Consider using later\n",
    "    gamesDF[\"POS\"] = gamesDF[\"FGA\"] - gamesDF[\"OR\"] + gamesDF[\"TO\"] + (0.4 * gamesDF[\"FTA\"])\n",
    "    sums = gamesDF.groupby(by = \"teamId\").sum().reset_index()\n",
    "    means = gamesDF.groupby(by = \"teamId\").mean().reset_index()\n",
    "\n",
    "    sums[\"oEff\"] = sums[\"score\"]/sums[\"POS\"]\n",
    "    sums[\"dEff\"] = sums[\"oppScore\"]/sums[\"POS\"]\n",
    "    sums[\"eFG\"] = (sums[\"FGM\"] + (0.5 + sums[\"FGM3\"])) / sums[\"FGA\"]\n",
    "    sums[\"FG%\"] = sums[\"FGM\"]/sums[\"FGA\"]\n",
    "    sums[\"3P%\"] = sums[\"FGM3\"]/sums[\"FGA3\"]\n",
    "    sums[\"3PP\"] = 3*sums[\"FGM3\"]/sums[\"score\"]\n",
    "    sums[\"FT%\"] = sums[\"FTM\"]/sums[\"FTA\"]\n",
    "    sums[\"2P%\"] = (sums[\"FGM\"] - sums[\"FGM3\"]) / (sums[\"FGA\"] - sums[\"FGA3\"])\n",
    "    sums[\"2PP\"] = 1 - sums[\"3PP\"]\n",
    "\n",
    "    meanSub = means[[\"teamId\", \"FTA\", \"OR\", \"DR\", \"TO\", \"TOF\", \"POS\", \"PF\"]]\n",
    "    sumSub = sums[[\"teamId\", \"oEff\", \"dEff\", \"eFG\", \"FG%\", \"3P%\", \"FT%\", \"3PP\", \"2P%\", \"2PP\"]]\n",
    "    stats = sumSub.merge(meanSub, how='left', left_on = \"teamId\", right_on = \"teamId\")\n",
    "    stats[\"season\"] = stats[\"teamId\"].apply(lambda x: x[x.index(\"_\") + 1:])\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstats for each team found from a certain year \\nseeds and rankings are found for each team from a certain year \\ndata frames are merged linking stats to seeds/ranks\\nmerged data frame is normalized to give all stats or ranks equal weight\\neach matchup from a year's tournament is used to calculate a score for each team\\nscore is calculated using the normalized features and the logic in the findScore function\\n- Offensive score, defensive score, ranking score that are combined \\n- weights used were based on four factors of basketball and then adjusted \\n\\nscore for both team is calculated and then used to create a new data frame for the corresponding matchup \\na score for both teams in each matchup is calculated and a data frame with those scores is created \\nA prediction for each matchup in data frame is found by looking at which team has highest calculated score \\n\\nmodel predictions are compared against baseline models based on how many games were picked accurately by year \\none tailed proportions test was done to test whether or not the models results were significant \\n\\n\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createModelMatchupsDF():\n",
    "    ranks = getRankings()\n",
    "    seeds = getSeeds()\n",
    "    seedsAndRanks = mergeSeedsAndRanks(seeds, ranks)\n",
    "    names = getTeamNames()\n",
    "    matchups = []\n",
    "    teamScoreInfo = []\n",
    "    visited = set()\n",
    "    for year in range(2003, 2018):\n",
    "        statsDF = setupStatsDF(year)\n",
    "        statsSeeds = mergeSeedsRanksStats(seedsAndRanks, statsDF)\n",
    "        normStats = normalizeFeatures(statsSeeds)\n",
    "        tournRes = pd.read_csv(\"data/NCAATourneyCompactResults.csv\")\n",
    "        tournRes = tournRes[tournRes[\"DayNum\"] > 135]\n",
    "        recentRes = tournRes[tournRes[\"Season\"] == year]\n",
    "\n",
    "        for index, row in recentRes.iterrows():\n",
    "            season = row[\"Season\"]\n",
    "            wTeamId = row[\"WTeamID\"]\n",
    "            lTeamId = row[\"LTeamID\"]\n",
    "            customWId = str(wTeamId) + \"_\" + str(season)\n",
    "            customLId = str(lTeamId) + \"_\" + str(season)\n",
    "            teamW = normStats[normStats[\"teamId\"] == customWId]\n",
    "            teamL = normStats[normStats[\"teamId\"] == customLId]\n",
    "            seedRankW = [teamW[\"RPI\"].values[0], teamW[\"POM\"].values[0], teamW[\"Seed\"].values[0]]\n",
    "            seedRankL = [teamL[\"RPI\"].values[0], teamL[\"POM\"].values[0], teamL[\"Seed\"].values[0]]\n",
    "            if not teamW.empty:\n",
    "                wScore = findScore(teamW, teamL)\n",
    "                lScore = findScore(teamL, teamW)\n",
    "                if customWId not in visited:\n",
    "                    teamScoreInfo.append(wScore)\n",
    "                    visited.add(customWId)\n",
    "                if customLId not in visited:\n",
    "                    teamScoreInfo.append(lScore)\n",
    "                    visited.add(customLId)\n",
    "                matchups.append([season, customWId, names[wTeamId], customLId, names[lTeamId], wScore[-1], lScore[-1]] + seedRankW + seedRankL)\n",
    "    matchDF = pd.DataFrame(matchups, columns = [\"season\", \"wId\", \"wName\", \"lId\", \"lName\", \"wScore\", \"lScore\", \n",
    "                                               \"wRPI\", \"wPOM\", \"wSeed\", \"lRPI\", \"lPOM\", \"lSeed\"])\n",
    "    matchDF[\"predicted\"] = matchDF[\"wScore\"] > matchDF[\"lScore\"]\n",
    "    matchDF[\"seedBaseline\"] = matchDF[\"wSeed\"] < matchDF[\"lSeed\"]\n",
    "    matchDF[\"pomBaseline\"] = matchDF[\"wPOM\"] < matchDF[\"lPOM\"]\n",
    "    matchDF[\"rpiBaseline\"] = matchDF[\"wRPI\"] < matchDF[\"lRPI\"]\n",
    "    matchDF.to_csv(\"data/output/matchupRes_regression.csv\", index = False)\n",
    "    return matchDF\n",
    "\n",
    "\"\"\"\n",
    "stats for each team found from a certain year \n",
    "seeds and rankings are found for each team from a certain year \n",
    "data frames are merged linking stats to seeds/ranks\n",
    "merged data frame is normalized to give all stats or ranks equal weight\n",
    "each matchup from a year's tournament is used to calculate a score for each team\n",
    "score is calculated using the normalized features and the logic in the findScore function\n",
    "- Offensive score, defensive score, ranking score that are combined \n",
    "- weights used were based on four factors of basketball and then adjusted \n",
    "\n",
    "score for both team is calculated and then used to create a new data frame for the corresponding matchup \n",
    "a score for both teams in each matchup is calculated and a data frame with those scores is created \n",
    "A prediction for each matchup in data frame is found by looking at which team has highest calculated score \n",
    "\n",
    "model predictions are compared against baseline models based on how many games were picked accurately by year \n",
    "one tailed proportions test was done to test whether or not the models results were significant \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no less than for seedbaseline\n",
    "modelComparisons = matchDF.groupby('season')[\"predicted\", \"seedBaseline\", \"pomBaseline\", \"rpiBaseline\"].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=2.1754067128234165, pvalue=0.047224674617508226)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel = np.array(modelComparisons [\"predicted\"])\n",
    "seed = np.array(modelComparisons[\"seedBaseline\"])\n",
    "np.random.seed(12345678)\n",
    "sciStats.ttest_rel(myModel,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
